{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset0.json.gz, dataset1.json.gz, dataset2.json.gz ==============================================================\n",
    "objs=[]\n",
    "with gzip.open(r\"/Users/tangyating/desktop/Group-Project/dataset0.json.gz\", 'rt') as f:\n",
    "    for line in f:\n",
    "        objs.append(json.loads(line))\n",
    "\n",
    "# Read data.info table ====================================================================================================\n",
    "data = pd.read_csv(r\"/Users/tangyating/desktop/Group-Project/data.info\")\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "rows = []\n",
    "for i in range(len(objs)):\n",
    "    for key1, inner_dict in objs[i].items():\n",
    "        for key2, inner_list in inner_dict.items():\n",
    "            for key3, sublist in inner_list.items():\n",
    "                for subsublist in sublist:\n",
    "                    rows.append([key1, key2, key3] + subsublist)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(rows, columns=[\"transcript_id\", \"transcript_position\", \"combined nucleotides\", \"dwelling_time1\", \"sd1\", \"mean1\", \"dwelling_time2\", \"sd2\", \"mean2\", \"dwelling_time3\", \"sd3\", \"mean3\"])\n",
    "\n",
    "df['transcript_position'] = df['transcript_position'].astype(int)\n",
    "data['transcript_position'] = data['transcript_position'].astype(int)\n",
    "\n",
    "df = pd.merge(df, data, on=['transcript_id', 'transcript_position'], how='inner')\n",
    "\n",
    "#df.to_csv('df.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>transcript_position</th>\n",
       "      <th>combined nucleotides</th>\n",
       "      <th>dwelling_time1</th>\n",
       "      <th>sd1</th>\n",
       "      <th>mean1</th>\n",
       "      <th>dwelling_time2</th>\n",
       "      <th>sd2</th>\n",
       "      <th>mean2</th>\n",
       "      <th>dwelling_time3</th>\n",
       "      <th>sd3</th>\n",
       "      <th>mean3</th>\n",
       "      <th>gene_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>0.00299</td>\n",
       "      <td>2.06</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.01770</td>\n",
       "      <td>10.40</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.00930</td>\n",
       "      <td>10.90</td>\n",
       "      <td>84.1</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>0.00631</td>\n",
       "      <td>2.53</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.00844</td>\n",
       "      <td>4.67</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.01030</td>\n",
       "      <td>6.30</td>\n",
       "      <td>80.9</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>3.92</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.01360</td>\n",
       "      <td>12.00</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.00498</td>\n",
       "      <td>2.13</td>\n",
       "      <td>79.6</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>0.00398</td>\n",
       "      <td>2.06</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.00830</td>\n",
       "      <td>5.01</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.00498</td>\n",
       "      <td>3.78</td>\n",
       "      <td>80.4</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>0.00664</td>\n",
       "      <td>2.92</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.00266</td>\n",
       "      <td>3.94</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.01300</td>\n",
       "      <td>7.15</td>\n",
       "      <td>82.2</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11027101</th>\n",
       "      <td>ENST00000641834</td>\n",
       "      <td>1693</td>\n",
       "      <td>TTGACAT</td>\n",
       "      <td>0.00418</td>\n",
       "      <td>7.49</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.00564</td>\n",
       "      <td>10.20</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>2.01</td>\n",
       "      <td>76.4</td>\n",
       "      <td>ENSG00000167747</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11027102</th>\n",
       "      <td>ENST00000641834</td>\n",
       "      <td>1693</td>\n",
       "      <td>TTGACAT</td>\n",
       "      <td>0.00664</td>\n",
       "      <td>1.91</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.00598</td>\n",
       "      <td>12.30</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.01760</td>\n",
       "      <td>2.61</td>\n",
       "      <td>74.6</td>\n",
       "      <td>ENSG00000167747</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11027103</th>\n",
       "      <td>ENST00000641834</td>\n",
       "      <td>1693</td>\n",
       "      <td>TTGACAT</td>\n",
       "      <td>0.00721</td>\n",
       "      <td>4.58</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.00398</td>\n",
       "      <td>6.58</td>\n",
       "      <td>113.0</td>\n",
       "      <td>0.00316</td>\n",
       "      <td>2.28</td>\n",
       "      <td>85.3</td>\n",
       "      <td>ENSG00000167747</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11027104</th>\n",
       "      <td>ENST00000641834</td>\n",
       "      <td>1693</td>\n",
       "      <td>TTGACAT</td>\n",
       "      <td>0.00266</td>\n",
       "      <td>2.33</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.00913</td>\n",
       "      <td>10.40</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.00664</td>\n",
       "      <td>4.44</td>\n",
       "      <td>76.8</td>\n",
       "      <td>ENSG00000167747</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11027105</th>\n",
       "      <td>ENST00000641834</td>\n",
       "      <td>1693</td>\n",
       "      <td>TTGACAT</td>\n",
       "      <td>0.00564</td>\n",
       "      <td>3.13</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.00303</td>\n",
       "      <td>9.98</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.01930</td>\n",
       "      <td>1.79</td>\n",
       "      <td>76.2</td>\n",
       "      <td>ENSG00000167747</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11027106 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            transcript_id  transcript_position combined nucleotides  \\\n",
       "0         ENST00000000233                  244              AAGACCA   \n",
       "1         ENST00000000233                  244              AAGACCA   \n",
       "2         ENST00000000233                  244              AAGACCA   \n",
       "3         ENST00000000233                  244              AAGACCA   \n",
       "4         ENST00000000233                  244              AAGACCA   \n",
       "...                   ...                  ...                  ...   \n",
       "11027101  ENST00000641834                 1693              TTGACAT   \n",
       "11027102  ENST00000641834                 1693              TTGACAT   \n",
       "11027103  ENST00000641834                 1693              TTGACAT   \n",
       "11027104  ENST00000641834                 1693              TTGACAT   \n",
       "11027105  ENST00000641834                 1693              TTGACAT   \n",
       "\n",
       "          dwelling_time1   sd1  mean1  dwelling_time2    sd2  mean2  \\\n",
       "0                0.00299  2.06  125.0         0.01770  10.40  122.0   \n",
       "1                0.00631  2.53  125.0         0.00844   4.67  126.0   \n",
       "2                0.00465  3.92  109.0         0.01360  12.00  124.0   \n",
       "3                0.00398  2.06  125.0         0.00830   5.01  130.0   \n",
       "4                0.00664  2.92  120.0         0.00266   3.94  129.0   \n",
       "...                  ...   ...    ...             ...    ...    ...   \n",
       "11027101         0.00418  7.49  108.0         0.00564  10.20  116.0   \n",
       "11027102         0.00664  1.91  109.0         0.00598  12.30  110.0   \n",
       "11027103         0.00721  4.58  105.0         0.00398   6.58  113.0   \n",
       "11027104         0.00266  2.33  109.0         0.00913  10.40  108.0   \n",
       "11027105         0.00564  3.13  110.0         0.00303   9.98  118.0   \n",
       "\n",
       "          dwelling_time3    sd3  mean3          gene_id  label  \n",
       "0                0.00930  10.90   84.1  ENSG00000004059      0  \n",
       "1                0.01030   6.30   80.9  ENSG00000004059      0  \n",
       "2                0.00498   2.13   79.6  ENSG00000004059      0  \n",
       "3                0.00498   3.78   80.4  ENSG00000004059      0  \n",
       "4                0.01300   7.15   82.2  ENSG00000004059      0  \n",
       "...                  ...    ...    ...              ...    ...  \n",
       "11027101         0.01000   2.01   76.4  ENSG00000167747      0  \n",
       "11027102         0.01760   2.61   74.6  ENSG00000167747      0  \n",
       "11027103         0.00316   2.28   85.3  ENSG00000167747      0  \n",
       "11027104         0.00664   4.44   76.8  ENSG00000167747      0  \n",
       "11027105         0.01930   1.79   76.2  ENSG00000167747      0  \n",
       "\n",
       "[11027106 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/tangyating/downloads/df.csv')\n",
    "\n",
    "agg_functions = {\n",
    "    'gene_id': 'first',\n",
    "    'combined nucleotides': 'first',\n",
    "    'dwelling_time1': 'mean',\n",
    "    'sd1': 'mean',\n",
    "    'mean1': 'mean',\n",
    "    'dwelling_time2': 'mean',\n",
    "    'sd2': 'mean',\n",
    "    'mean2': 'mean',\n",
    "    'dwelling_time3': 'mean',\n",
    "    'sd3': 'mean',\n",
    "    'mean3': 'mean',\n",
    "    'label': 'sum'\n",
    "}\n",
    "\n",
    "summary_df = df.groupby(['transcript_id', 'transcript_position']).agg(agg_functions).reset_index()\n",
    "summary_df['count'] = df.groupby(['transcript_id', 'transcript_position']).size().reset_index(name='count')['count']\n",
    "summary_df['label_percentage'] = summary_df['label'] / summary_df['count'] * 100\n",
    "summary_df = summary_df.rename(columns={'label': 'label_sum'})\n",
    "summary_df['label'] = summary_df['label_percentage'].apply(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "#summary_df.to_csv(\"summary_df.csv\")\n",
    "summary_df.to_pickle(\"/Users/tangyating/downloads/summary_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve, precision_recall_curve\n",
    "\n",
    "df = pd.read_pickle('/Users/tangyating/downloads/df.pkl')\n",
    "count_df = df.groupby(['transcript_id', 'transcript_position']).size().reset_index(name='count')\n",
    "df = df.merge(count_df, on=['transcript_id', 'transcript_position'])\n",
    "\n",
    "summary_df = pd.read_pickle('/Users/tangyating/downloads/summary_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>transcript_position</th>\n",
       "      <th>combined nucleotides</th>\n",
       "      <th>dwelling_time1</th>\n",
       "      <th>sd1</th>\n",
       "      <th>mean1</th>\n",
       "      <th>dwelling_time2</th>\n",
       "      <th>sd2</th>\n",
       "      <th>mean2</th>\n",
       "      <th>dwelling_time3</th>\n",
       "      <th>sd3</th>\n",
       "      <th>mean3</th>\n",
       "      <th>gene_id</th>\n",
       "      <th>label</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>0.00299</td>\n",
       "      <td>2.06</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.01770</td>\n",
       "      <td>10.40</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.00930</td>\n",
       "      <td>10.90</td>\n",
       "      <td>84.1</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>0.00631</td>\n",
       "      <td>2.53</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.00844</td>\n",
       "      <td>4.67</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.01030</td>\n",
       "      <td>6.30</td>\n",
       "      <td>80.9</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>3.92</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.01360</td>\n",
       "      <td>12.00</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.00498</td>\n",
       "      <td>2.13</td>\n",
       "      <td>79.6</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>0.00398</td>\n",
       "      <td>2.06</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.00830</td>\n",
       "      <td>5.01</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.00498</td>\n",
       "      <td>3.78</td>\n",
       "      <td>80.4</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>0.00664</td>\n",
       "      <td>2.92</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.00266</td>\n",
       "      <td>3.94</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.01300</td>\n",
       "      <td>7.15</td>\n",
       "      <td>82.2</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11027101</th>\n",
       "      <td>ENST00000641834</td>\n",
       "      <td>1693</td>\n",
       "      <td>TTGACAT</td>\n",
       "      <td>0.00418</td>\n",
       "      <td>7.49</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.00564</td>\n",
       "      <td>10.20</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>2.01</td>\n",
       "      <td>76.4</td>\n",
       "      <td>ENSG00000167747</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11027102</th>\n",
       "      <td>ENST00000641834</td>\n",
       "      <td>1693</td>\n",
       "      <td>TTGACAT</td>\n",
       "      <td>0.00664</td>\n",
       "      <td>1.91</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.00598</td>\n",
       "      <td>12.30</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.01760</td>\n",
       "      <td>2.61</td>\n",
       "      <td>74.6</td>\n",
       "      <td>ENSG00000167747</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11027103</th>\n",
       "      <td>ENST00000641834</td>\n",
       "      <td>1693</td>\n",
       "      <td>TTGACAT</td>\n",
       "      <td>0.00721</td>\n",
       "      <td>4.58</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.00398</td>\n",
       "      <td>6.58</td>\n",
       "      <td>113.0</td>\n",
       "      <td>0.00316</td>\n",
       "      <td>2.28</td>\n",
       "      <td>85.3</td>\n",
       "      <td>ENSG00000167747</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11027104</th>\n",
       "      <td>ENST00000641834</td>\n",
       "      <td>1693</td>\n",
       "      <td>TTGACAT</td>\n",
       "      <td>0.00266</td>\n",
       "      <td>2.33</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.00913</td>\n",
       "      <td>10.40</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.00664</td>\n",
       "      <td>4.44</td>\n",
       "      <td>76.8</td>\n",
       "      <td>ENSG00000167747</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11027105</th>\n",
       "      <td>ENST00000641834</td>\n",
       "      <td>1693</td>\n",
       "      <td>TTGACAT</td>\n",
       "      <td>0.00564</td>\n",
       "      <td>3.13</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.00303</td>\n",
       "      <td>9.98</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.01930</td>\n",
       "      <td>1.79</td>\n",
       "      <td>76.2</td>\n",
       "      <td>ENSG00000167747</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11027106 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            transcript_id  transcript_position combined nucleotides  \\\n",
       "0         ENST00000000233                  244              AAGACCA   \n",
       "1         ENST00000000233                  244              AAGACCA   \n",
       "2         ENST00000000233                  244              AAGACCA   \n",
       "3         ENST00000000233                  244              AAGACCA   \n",
       "4         ENST00000000233                  244              AAGACCA   \n",
       "...                   ...                  ...                  ...   \n",
       "11027101  ENST00000641834                 1693              TTGACAT   \n",
       "11027102  ENST00000641834                 1693              TTGACAT   \n",
       "11027103  ENST00000641834                 1693              TTGACAT   \n",
       "11027104  ENST00000641834                 1693              TTGACAT   \n",
       "11027105  ENST00000641834                 1693              TTGACAT   \n",
       "\n",
       "          dwelling_time1   sd1  mean1  dwelling_time2    sd2  mean2  \\\n",
       "0                0.00299  2.06  125.0         0.01770  10.40  122.0   \n",
       "1                0.00631  2.53  125.0         0.00844   4.67  126.0   \n",
       "2                0.00465  3.92  109.0         0.01360  12.00  124.0   \n",
       "3                0.00398  2.06  125.0         0.00830   5.01  130.0   \n",
       "4                0.00664  2.92  120.0         0.00266   3.94  129.0   \n",
       "...                  ...   ...    ...             ...    ...    ...   \n",
       "11027101         0.00418  7.49  108.0         0.00564  10.20  116.0   \n",
       "11027102         0.00664  1.91  109.0         0.00598  12.30  110.0   \n",
       "11027103         0.00721  4.58  105.0         0.00398   6.58  113.0   \n",
       "11027104         0.00266  2.33  109.0         0.00913  10.40  108.0   \n",
       "11027105         0.00564  3.13  110.0         0.00303   9.98  118.0   \n",
       "\n",
       "          dwelling_time3    sd3  mean3          gene_id  label  count  \n",
       "0                0.00930  10.90   84.1  ENSG00000004059      0    185  \n",
       "1                0.01030   6.30   80.9  ENSG00000004059      0    185  \n",
       "2                0.00498   2.13   79.6  ENSG00000004059      0    185  \n",
       "3                0.00498   3.78   80.4  ENSG00000004059      0    185  \n",
       "4                0.01300   7.15   82.2  ENSG00000004059      0    185  \n",
       "...                  ...    ...    ...              ...    ...    ...  \n",
       "11027101         0.01000   2.01   76.4  ENSG00000167747      0     52  \n",
       "11027102         0.01760   2.61   74.6  ENSG00000167747      0     52  \n",
       "11027103         0.00316   2.28   85.3  ENSG00000167747      0     52  \n",
       "11027104         0.00664   4.44   76.8  ENSG00000167747      0     52  \n",
       "11027105         0.01930   1.79   76.2  ENSG00000167747      0     52  \n",
       "\n",
       "[11027106 rows x 15 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>transcript_position</th>\n",
       "      <th>gene_id</th>\n",
       "      <th>combined nucleotides</th>\n",
       "      <th>dwelling_time1</th>\n",
       "      <th>sd1</th>\n",
       "      <th>mean1</th>\n",
       "      <th>dwelling_time2</th>\n",
       "      <th>sd2</th>\n",
       "      <th>mean2</th>\n",
       "      <th>dwelling_time3</th>\n",
       "      <th>sd3</th>\n",
       "      <th>mean3</th>\n",
       "      <th>label_sum</th>\n",
       "      <th>count</th>\n",
       "      <th>label_percentage</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>4.223784</td>\n",
       "      <td>123.702703</td>\n",
       "      <td>0.009373</td>\n",
       "      <td>7.382162</td>\n",
       "      <td>125.913514</td>\n",
       "      <td>0.007345</td>\n",
       "      <td>4.386989</td>\n",
       "      <td>80.570270</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>261</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>CAAACTG</td>\n",
       "      <td>0.006609</td>\n",
       "      <td>3.216424</td>\n",
       "      <td>109.681395</td>\n",
       "      <td>0.006813</td>\n",
       "      <td>3.226535</td>\n",
       "      <td>107.889535</td>\n",
       "      <td>0.007710</td>\n",
       "      <td>3.016599</td>\n",
       "      <td>94.290698</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>316</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>GAAACAG</td>\n",
       "      <td>0.007570</td>\n",
       "      <td>2.940541</td>\n",
       "      <td>105.475676</td>\n",
       "      <td>0.007416</td>\n",
       "      <td>3.642703</td>\n",
       "      <td>98.947027</td>\n",
       "      <td>0.007555</td>\n",
       "      <td>2.087146</td>\n",
       "      <td>89.364324</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>332</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>AGAACAT</td>\n",
       "      <td>0.010620</td>\n",
       "      <td>6.476350</td>\n",
       "      <td>129.355000</td>\n",
       "      <td>0.008632</td>\n",
       "      <td>2.899200</td>\n",
       "      <td>97.836500</td>\n",
       "      <td>0.006101</td>\n",
       "      <td>2.236520</td>\n",
       "      <td>89.154000</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>368</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>AGGACAA</td>\n",
       "      <td>0.010701</td>\n",
       "      <td>6.415051</td>\n",
       "      <td>117.924242</td>\n",
       "      <td>0.011479</td>\n",
       "      <td>5.870303</td>\n",
       "      <td>121.954545</td>\n",
       "      <td>0.010019</td>\n",
       "      <td>4.260253</td>\n",
       "      <td>85.178788</td>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121833</th>\n",
       "      <td>ENST00000641834</td>\n",
       "      <td>1348</td>\n",
       "      <td>ENSG00000167747</td>\n",
       "      <td>GGGACAT</td>\n",
       "      <td>0.009594</td>\n",
       "      <td>3.294164</td>\n",
       "      <td>118.232877</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>4.929726</td>\n",
       "      <td>116.342466</td>\n",
       "      <td>0.006555</td>\n",
       "      <td>4.005616</td>\n",
       "      <td>82.004110</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121834</th>\n",
       "      <td>ENST00000641834</td>\n",
       "      <td>1429</td>\n",
       "      <td>ENSG00000167747</td>\n",
       "      <td>CTGACAC</td>\n",
       "      <td>0.008393</td>\n",
       "      <td>4.511014</td>\n",
       "      <td>110.969565</td>\n",
       "      <td>0.010305</td>\n",
       "      <td>9.105797</td>\n",
       "      <td>114.927536</td>\n",
       "      <td>0.005568</td>\n",
       "      <td>3.644638</td>\n",
       "      <td>80.497101</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121835</th>\n",
       "      <td>ENST00000641834</td>\n",
       "      <td>1531</td>\n",
       "      <td>ENSG00000167747</td>\n",
       "      <td>TGGACAC</td>\n",
       "      <td>0.008161</td>\n",
       "      <td>3.918438</td>\n",
       "      <td>113.968750</td>\n",
       "      <td>0.006877</td>\n",
       "      <td>4.759688</td>\n",
       "      <td>113.562500</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>2.181563</td>\n",
       "      <td>84.190625</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121836</th>\n",
       "      <td>ENST00000641834</td>\n",
       "      <td>1537</td>\n",
       "      <td>ENSG00000167747</td>\n",
       "      <td>CTGACCA</td>\n",
       "      <td>0.008044</td>\n",
       "      <td>3.191228</td>\n",
       "      <td>109.354386</td>\n",
       "      <td>0.007419</td>\n",
       "      <td>6.552982</td>\n",
       "      <td>123.263158</td>\n",
       "      <td>0.006472</td>\n",
       "      <td>2.540877</td>\n",
       "      <td>82.289474</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121837</th>\n",
       "      <td>ENST00000641834</td>\n",
       "      <td>1693</td>\n",
       "      <td>ENSG00000167747</td>\n",
       "      <td>TTGACAT</td>\n",
       "      <td>0.008788</td>\n",
       "      <td>4.090577</td>\n",
       "      <td>105.807692</td>\n",
       "      <td>0.006908</td>\n",
       "      <td>8.702885</td>\n",
       "      <td>113.134615</td>\n",
       "      <td>0.008337</td>\n",
       "      <td>2.576731</td>\n",
       "      <td>78.536538</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121838 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          transcript_id  transcript_position          gene_id  \\\n",
       "0       ENST00000000233                  244  ENSG00000004059   \n",
       "1       ENST00000000233                  261  ENSG00000004059   \n",
       "2       ENST00000000233                  316  ENSG00000004059   \n",
       "3       ENST00000000233                  332  ENSG00000004059   \n",
       "4       ENST00000000233                  368  ENSG00000004059   \n",
       "...                 ...                  ...              ...   \n",
       "121833  ENST00000641834                 1348  ENSG00000167747   \n",
       "121834  ENST00000641834                 1429  ENSG00000167747   \n",
       "121835  ENST00000641834                 1531  ENSG00000167747   \n",
       "121836  ENST00000641834                 1537  ENSG00000167747   \n",
       "121837  ENST00000641834                 1693  ENSG00000167747   \n",
       "\n",
       "       combined nucleotides  dwelling_time1       sd1       mean1  \\\n",
       "0                   AAGACCA        0.008264  4.223784  123.702703   \n",
       "1                   CAAACTG        0.006609  3.216424  109.681395   \n",
       "2                   GAAACAG        0.007570  2.940541  105.475676   \n",
       "3                   AGAACAT        0.010620  6.476350  129.355000   \n",
       "4                   AGGACAA        0.010701  6.415051  117.924242   \n",
       "...                     ...             ...       ...         ...   \n",
       "121833              GGGACAT        0.009594  3.294164  118.232877   \n",
       "121834              CTGACAC        0.008393  4.511014  110.969565   \n",
       "121835              TGGACAC        0.008161  3.918438  113.968750   \n",
       "121836              CTGACCA        0.008044  3.191228  109.354386   \n",
       "121837              TTGACAT        0.008788  4.090577  105.807692   \n",
       "\n",
       "        dwelling_time2       sd2       mean2  dwelling_time3       sd3  \\\n",
       "0             0.009373  7.382162  125.913514        0.007345  4.386989   \n",
       "1             0.006813  3.226535  107.889535        0.007710  3.016599   \n",
       "2             0.007416  3.642703   98.947027        0.007555  2.087146   \n",
       "3             0.008632  2.899200   97.836500        0.006101  2.236520   \n",
       "4             0.011479  5.870303  121.954545        0.010019  4.260253   \n",
       "...                ...       ...         ...             ...       ...   \n",
       "121833        0.007300  4.929726  116.342466        0.006555  4.005616   \n",
       "121834        0.010305  9.105797  114.927536        0.005568  3.644638   \n",
       "121835        0.006877  4.759688  113.562500        0.006410  2.181563   \n",
       "121836        0.007419  6.552982  123.263158        0.006472  2.540877   \n",
       "121837        0.006908  8.702885  113.134615        0.008337  2.576731   \n",
       "\n",
       "            mean3  label_sum  count  label_percentage  label  \n",
       "0       80.570270          0    185               0.0      0  \n",
       "1       94.290698          0    172               0.0      0  \n",
       "2       89.364324          0    185               0.0      0  \n",
       "3       89.154000          0    200               0.0      0  \n",
       "4       85.178788          0    198               0.0      0  \n",
       "...           ...        ...    ...               ...    ...  \n",
       "121833  82.004110         73     73             100.0      1  \n",
       "121834  80.497101          0     69               0.0      0  \n",
       "121835  84.190625         64     64             100.0      1  \n",
       "121836  82.289474          0     57               0.0      0  \n",
       "121837  78.536538          0     52               0.0      0  \n",
       "\n",
       "[121838 rows x 17 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================================================================================================\n",
    "# Using rus to deal with imbalanced dataset, Train and test data on df ==========================================================================================\n",
    "# ===============================================================================================================================================================\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve, precision_recall_curve\n",
    "\n",
    "combined = df\n",
    "label_encoder = LabelEncoder()\n",
    "combined['transcript_id'] = label_encoder.fit_transform(combined['transcript_id'])\n",
    "combined['gene_id'] = label_encoder.fit_transform(combined['gene_id'])\n",
    "combined = pd.get_dummies(combined, columns=['combined nucleotides'], prefix='nucleotide', drop_first=True)\n",
    "\n",
    "X = combined.drop('label', axis=1)\n",
    "y = combined['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_usampled, y_usampled = rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 300}\n",
      "Accuracy_xgb: 0.8247559877429353\n",
      "Confusion Matrix_xgb:\n",
      " [[1732419  373088]\n",
      " [  13399   86516]]\n",
      "Classification Report_xgb:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.82      0.90   2105507\n",
      "           1       0.19      0.87      0.31     99915\n",
      "\n",
      "    accuracy                           0.82   2205422\n",
      "   macro avg       0.59      0.84      0.60   2205422\n",
      "weighted avg       0.96      0.82      0.87   2205422\n",
      "\n",
      "ROC AUC Score: 0.844349867684282\n"
     ]
    }
   ],
   "source": [
    "# XG Boost\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve, precision_recall_curve\n",
    "\n",
    "best_params = {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 300}\n",
    "xgb_model = xgb.XGBClassifier(**best_params)\n",
    "xgb_model.fit(X_usampled, y_usampled)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Calculate and print evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_xgb)\n",
    "confusion = confusion_matrix(y_test, y_pred_xgb)\n",
    "classification_report_str = classification_report(y_test, y_pred_xgb)\n",
    "roc_auc_xgb = roc_auc_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Accuracy_xgb:\", accuracy)\n",
    "print(\"Confusion Matrix_xgb:\\n\", confusion)\n",
    "print(\"Classification Report_xgb:\\n\", classification_report_str)\n",
    "print(\"ROC AUC Score:\", roc_auc_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8139094238044571"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "predictions_df_xgb = pd.DataFrame({'y_pred_xgb': y_pred_xgb})\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)\n",
    "predictions_df_xgb.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_with_predictions_xgb = pd.concat([X_test, y_test, predictions_df_xgb], axis=1)\n",
    "\n",
    "mean_predictions = df_with_predictions_xgb.groupby(['transcript_id', 'transcript_position'])['y_pred_xgb'].mean()\n",
    "y_test_xgb = df_with_predictions_xgb.groupby(['transcript_id', 'transcript_position'])['label'].mean()\n",
    "mean_predictions = mean_predictions.rename('y_pred_xgb_mean')\n",
    "y_test_xgb = y_test_xgb.rename('y_test_xgb_mean')\n",
    "\n",
    "mean_predictions_df = mean_predictions.reset_index()\n",
    "y_test_xgb_df = y_test_xgb.reset_index()\n",
    "\n",
    "result_df = pd.concat([mean_predictions_df, y_test_xgb_df['y_test_xgb_mean']], axis=1)\n",
    "result_df\n",
    "\n",
    "threshold = 0.5\n",
    "result_df['y_pred_xgb_binary'] = np.where(result_df['y_pred_xgb_mean'] >= threshold, 1, 0)\n",
    "\n",
    "roc_auc_xgb_agg = roc_auc_score(result_df['y_test_xgb_mean'], result_df['y_pred_xgb_binary'])\n",
    "roc_auc_xgb_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 10, 'min_samples_split': 5}\n",
      "Accuracy_rf: 0.71952306633379\n",
      "Confusion Matrix_rf:\n",
      " [[1509058  596449]\n",
      " [  22121   77794]]\n",
      "Classification Report_rf:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.72      0.83   2105507\n",
      "           1       0.12      0.78      0.20     99915\n",
      "\n",
      "    accuracy                           0.72   2205422\n",
      "   macro avg       0.55      0.75      0.52   2205422\n",
      "weighted avg       0.95      0.72      0.80   2205422\n",
      "\n",
      "ROC AUC Score_rf: 0.8294662862132984\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [10],\n",
    "    'min_samples_split': [5],\n",
    "}\n",
    "\n",
    "rf_grid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='roc_auc')\n",
    "rf_grid_search.fit(X_usampled, y_usampled)\n",
    "\n",
    "best_model = rf_grid_search.best_estimator_\n",
    "best_params = rf_grid_search.best_params_\n",
    "\n",
    "best_model.n_estimators = 100\n",
    "y_pred_rf = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "threshold = 0.5\n",
    "y_pred_rf_binary = (y_pred_rf >= threshold).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_rf_binary)\n",
    "confusion = confusion_matrix(y_test, y_pred_rf_binary)\n",
    "classification_report_str = classification_report(y_test, y_pred_rf_binary)\n",
    "roc_auc_rf = roc_auc_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Accuracy_rf:\", accuracy)\n",
    "print(\"Confusion Matrix_rf:\\n\", confusion)\n",
    "print(\"Classification Report_rf:\\n\", classification_report_str)\n",
    "print(\"ROC AUC Score_rf:\", roc_auc_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7357229568359933"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "predictions_df_rf = pd.DataFrame({'y_pred_rf': y_pred_rf})\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)\n",
    "predictions_df_rf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_with_predictions_rf = pd.concat([X_test, y_test, predictions_df_rf], axis=1)\n",
    "\n",
    "mean_predictions = df_with_predictions_rf.groupby(['transcript_id', 'transcript_position'])['y_pred_rf'].mean()\n",
    "y_test_rf = df_with_predictions_rf.groupby(['transcript_id', 'transcript_position'])['label'].mean()\n",
    "mean_predictions = mean_predictions.rename('y_pred_rf_mean')\n",
    "y_test_rf = y_test_rf.rename('y_test_rf_mean')\n",
    "\n",
    "mean_predictions_df = mean_predictions.reset_index()\n",
    "y_test_rf_df = y_test_rf.reset_index()\n",
    "\n",
    "result_df = pd.concat([mean_predictions_df, y_test_rf_df['y_test_rf_mean']], axis=1)\n",
    "result_df\n",
    "\n",
    "threshold = 0.5\n",
    "result_df['y_pred_rf_binary'] = np.where(result_df['y_pred_rf_mean'] >= threshold, 1, 0)\n",
    "\n",
    "roc_auc_rf_agg = roc_auc_score(result_df['y_test_rf_mean'], result_df['y_pred_rf_binary'])\n",
    "roc_auc_rf_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve, precision_recall_curve\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_usampled, y_usampled)\n",
    "y_pred_lg = logistic_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "threshold = 0.5\n",
    "y_pred_lg_binary = (y_pred_lg >= threshold).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_lg_binary)\n",
    "confusion = confusion_matrix(y_test, y_pred_lg_binary)\n",
    "classification_report_str = classification_report(y_test, y_pred_lg_binary)\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_pred_lg)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_lg)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_lg)\n",
    "\n",
    "print(\"Accuracy_lg:\", accuracy)\n",
    "print(\"Confusion Matrix_lg:\\n\", confusion)\n",
    "print(\"Classification Report_lg:\\n\", classification_report_str)\n",
    "print(\"ROC AUC Score_lg:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 300}\n",
      "Accuracy_lg: 0.8247559877429353\n",
      "Confusion Matrix_lg:\n",
      " [[1732419  373088]\n",
      " [  13399   86516]]\n",
      "Classification Report_lg:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.82      0.90   2105507\n",
      "           1       0.19      0.87      0.31     99915\n",
      "\n",
      "    accuracy                           0.82   2205422\n",
      "   macro avg       0.59      0.84      0.60   2205422\n",
      "weighted avg       0.96      0.82      0.87   2205422\n",
      "\n",
      "ROC AUC Score of Gradient Boosting (XGBoost): 0.9276959475222228\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting (XGBoost) for Classification\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "}\n",
    "\n",
    "xgb_grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='roc_auc', cv=5)\n",
    "xgb_grid_search.fit(X_usampled, y_usampled)\n",
    "\n",
    "best_model = xgb_grid_search.best_estimator_\n",
    "best_params = xgb_grid_search.best_params_\n",
    "\n",
    "y_pred_gb = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "threshold = 0.5\n",
    "y_pred_gb_binary = (y_pred_gb >= threshold).astype(int)\n",
    "\n",
    "roc_auc_gb = roc_auc_score(y_test, y_pred_gb)\n",
    "accuracy = accuracy_score(y_test, y_pred_gb_binary)\n",
    "confusion = confusion_matrix(y_test, y_pred_gb_binary)\n",
    "classification_report_str = classification_report(y_test, y_pred_gb_binary)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Accuracy_lg:\", accuracy)\n",
    "print(\"Confusion Matrix_lg:\\n\", confusion)\n",
    "print(\"Classification Report_lg:\\n\", classification_report_str)\n",
    "print(\"ROC AUC Score of Gradient Boosting (XGBoost):\", roc_auc_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8151117365037728"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "predictions_df_gb = pd.DataFrame({'y_pred_gb': y_pred_gb})\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)\n",
    "predictions_df_gb.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_with_predictions_gb = pd.concat([X_test, y_test, predictions_df_gb], axis=1)\n",
    "\n",
    "mean_predictions = df_with_predictions_gb.groupby(['transcript_id', 'transcript_position'])['y_pred_gb'].mean()\n",
    "y_test_gb = df_with_predictions_gb.groupby(['transcript_id', 'transcript_position'])['label'].mean()\n",
    "mean_predictions = mean_predictions.rename('y_pred_gb_mean')\n",
    "y_test_gb = y_test_gb.rename('y_test_gb_mean')\n",
    "\n",
    "mean_predictions_df = mean_predictions.reset_index()\n",
    "y_test_gb_df = y_test_gb.reset_index()\n",
    "\n",
    "result_df = pd.concat([mean_predictions_df, y_test_gb_df['y_test_gb_mean']], axis=1)\n",
    "result_df\n",
    "\n",
    "threshold = 0.5\n",
    "result_df['y_pred_gb_binary'] = np.where(result_df['y_pred_gb_mean'] >= threshold, 1, 0)\n",
    "\n",
    "roc_auc_gb_agg = roc_auc_score(result_df['y_test_gb_mean'], result_df['y_pred_gb_binary'])\n",
    "\n",
    "roc_auc_gb_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lr/2nfz4tks7jvdbfs0vc58q0x00000gn/T/ipykernel_41847/2298579575.py:20: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_classifier = tf.keras.wrappers.scikit_learn.KerasClassifier(build_fn=create_model, verbose=0)\n",
      "2023-10-22 13:40:47.764226: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Neural Networks (Feedforward) for Classification\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def create_model(neurons_in_input=64, neurons_in_hidden=32, learning_rate=0.001):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(neurons_in_input, activation='relu', input_shape=(input_dim,), name='input_layer'),\n",
    "        tf.keras.layers.Dense(neurons_in_hidden, activation='relu', name='hidden_layer'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid', name='output_layer')\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
    "    return model\n",
    "\n",
    "input_dim = 300\n",
    "keras_classifier = tf.keras.wrappers.scikit_learn.KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "param_grid = {\n",
    "    'neurons_in_input': [64, 128],\n",
    "    'neurons_in_hidden': [32, 64],\n",
    "    'learning_rate': [0.001, 0.01]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(keras_classifier, param_grid, cv=StratifiedKFold(n_splits=3), scoring='roc_auc')\n",
    "grid_search.fit(X_usampled, y_usampled, epochs=10, batch_size=32)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "y_pred_nn = best_model.predict(X_test).flatten()\n",
    "\n",
    "threshold = 0.5\n",
    "y_pred_nn_binary = (y_pred_nn >= threshold).astype(int)\n",
    "\n",
    "roc_auc_nn = roc_auc_score(y_test, y_pred_nn)\n",
    "accuracy = accuracy_score(y_test, y_pred_nn_binary)\n",
    "confusion = confusion_matrix(y_test, y_pred_nn_binary)\n",
    "classification_report_str = classification_report(y_test, y_pred_nn_binary)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Accuracy_nn:\", accuracy)\n",
    "print(\"Confusion Matrix_nn:\\n\", confusion)\n",
    "print(\"Classification Report_nn:\\n\", classification_report_str)\n",
    "print(\"ROC AUC Score of Neural Networks:\", roc_auc_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "predictions_df_nn = pd.DataFrame({'y_pred_nn': y_pred_nn})\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)\n",
    "predictions_df_nn.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_with_predictions_nn = pd.concat([X_test, y_test, predictions_df_nn], axis=1)\n",
    "\n",
    "mean_predictions = df_with_predictions_nn.groupby(['transcript_id', 'transcript_position'])['y_pred_nn'].mean()\n",
    "y_test_nn = df_with_predictions_nn.groupby(['transcript_id', 'transcript_position'])['label'].mean()\n",
    "mean_predictions = mean_predictions.rename('y_pred_nn_mean')\n",
    "y_test_nn = y_test_nn.rename('y_test_nn_mean')\n",
    "\n",
    "mean_predictions_df = mean_predictions.reset_index()\n",
    "y_test_nn_df = y_test_nn.reset_index()\n",
    "\n",
    "result_df = pd.concat([mean_predictions_df, y_test_nn_df['y_test_nn_mean']], axis=1)\n",
    "result_df\n",
    "\n",
    "threshold = 0.5\n",
    "result_df['y_pred_nn_binary'] = np.where(result_df['y_pred_nn_mean'] >= threshold, 1, 0)\n",
    "\n",
    "roc_auc_nn_agg = roc_auc_score(result_df['y_test_nn_mean'], result_df['y_pred_nn_binary'])\n",
    "roc_auc_nn_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================================================================================================\n",
    "# Using rus to deal with imbalanced dataset, Train and test data on summary_df ==================================================================================\n",
    "# ===============================================================================================================================================================\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve, precision_recall_curve\n",
    "\n",
    "combined = summary_df\n",
    "label_encoder = LabelEncoder()\n",
    "combined['transcript_id'] = label_encoder.fit_transform(combined['transcript_id'])\n",
    "combined['gene_id'] = label_encoder.fit_transform(combined['gene_id'])\n",
    "combined = pd.get_dummies(combined, columns=['combined nucleotides'], prefix='nucleotide', drop_first=True)\n",
    "\n",
    "X = combined.drop(['label', 'label_percentage', 'label_sum'], axis=1)\n",
    "y = combined['label']\n",
    "X_train_summary, X_test_summary, y_train_summary, y_test_summary = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_usampled_summary, y_usampled_summary = rus.fit_resample(X_train_summary, y_train_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 300}\n",
      "Accuracy_xgb: 0.8294484569927774\n",
      "Confusion Matrix_xgb:\n",
      " [[19349  3924]\n",
      " [  232   863]]\n",
      "Classification Report_xgb:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.83      0.90     23273\n",
      "           1       0.18      0.79      0.29      1095\n",
      "\n",
      "    accuracy                           0.83     24368\n",
      "   macro avg       0.58      0.81      0.60     24368\n",
      "weighted avg       0.95      0.83      0.88     24368\n",
      "\n",
      "ROC AUC Score: 0.8097602273746185\n"
     ]
    }
   ],
   "source": [
    "# XG Boost\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "}\n",
    "\n",
    "xgb_grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='roc_auc', cv=5)\n",
    "xgb_grid_search.fit(X_usampled_summary, y_usampled_summary)\n",
    "\n",
    "best_params = xgb_grid_search.best_params_\n",
    "best_model = xgb_grid_search.best_estimator_\n",
    "\n",
    "y_pred_xgb = best_model.predict(X_test_summary)\n",
    "\n",
    "# Calculate and print evaluation metrics\n",
    "accuracy = accuracy_score(y_test_summary, y_pred_xgb)\n",
    "confusion = confusion_matrix(y_test_summary, y_pred_xgb)\n",
    "classification_report_str = classification_report(y_test_summary, y_pred_xgb)\n",
    "roc_auc_xgb = roc_auc_score(y_test_summary, y_pred_xgb)\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Accuracy_xgb:\", accuracy)\n",
    "print(\"Confusion Matrix_xgb:\\n\", confusion)\n",
    "print(\"Classification Report_xgb:\\n\", classification_report_str)\n",
    "print(\"ROC AUC Score:\", roc_auc_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Accuracy_rf: 0.8107353906762967\n",
      "Confusion Matrix_rf:\n",
      " [[18870  4403]\n",
      " [  209   886]]\n",
      "Classification Report_rf:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.81      0.89     23273\n",
      "           1       0.17      0.81      0.28      1095\n",
      "\n",
      "    accuracy                           0.81     24368\n",
      "   macro avg       0.58      0.81      0.58     24368\n",
      "weighted avg       0.95      0.81      0.86     24368\n",
      "\n",
      "ROC AUC Score_rf: 0.8933163579329487\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, scoring='roc_auc', cv=5)\n",
    "\n",
    "rf_grid_search.fit(X_usampled_summary, y_usampled_summary)\n",
    "\n",
    "best_params = rf_grid_search.best_params_\n",
    "best_rf_model = rf_grid_search.best_estimator_\n",
    "\n",
    "y_pred_rf = best_rf_model.predict_proba(X_test_summary)[:, 1]\n",
    "\n",
    "threshold = 0.5\n",
    "y_pred_rf_binary = (y_pred_rf >= threshold).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_test_summary, y_pred_rf_binary)\n",
    "confusion = confusion_matrix(y_test_summary, y_pred_rf_binary)\n",
    "classification_report_str = classification_report(y_test_summary, y_pred_rf_binary)\n",
    "roc_auc_rf_summary = roc_auc_score(y_test_summary, y_pred_rf)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Accuracy_rf:\", accuracy)\n",
    "print(\"Confusion Matrix_rf:\\n\", confusion)\n",
    "print(\"Classification Report_rf:\\n\", classification_report_str)\n",
    "print(\"ROC AUC Score_rf:\", roc_auc_rf_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tangyating/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tangyating/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tangyating/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tangyating/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tangyating/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tangyating/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tangyating/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tangyating/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tangyating/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tangyating/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tangyating/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tangyating/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tangyating/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tangyating/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tangyating/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tangyating/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tangyating/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tangyating/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tangyating/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tangyating/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tangyating/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tangyating/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tangyating/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tangyating/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tangyating/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/tangyating/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "25 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tangyating/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tangyating/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/tangyating/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/tangyating/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.66079158        nan 0.66633593        nan 0.66705135\n",
      "        nan 0.66289146        nan 0.65932502]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 0.1, 'penalty': 'l2'}\n",
      "Accuracy_lg: 0.6139609323703218\n",
      "Confusion Matrix_lg:\n",
      " [[14239  9034]\n",
      " [  373   722]]\n",
      "Classification Report_lg:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.61      0.75     23273\n",
      "           1       0.07      0.66      0.13      1095\n",
      "\n",
      "    accuracy                           0.61     24368\n",
      "   macro avg       0.52      0.64      0.44     24368\n",
      "weighted avg       0.93      0.61      0.72     24368\n",
      "\n",
      "ROC AUC Score_lg: 0.6694535596641571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tangyating/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "}\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "lg_grid_search = GridSearchCV(estimator=logistic_model, param_grid=param_grid, scoring='roc_auc', cv=5)\n",
    "\n",
    "lg_grid_search.fit(X_usampled_summary, y_usampled_summary)\n",
    "\n",
    "best_params = lg_grid_search.best_params_\n",
    "best_lg_model = lg_grid_search.best_estimator_\n",
    "\n",
    "y_pred_lg = best_lg_model.predict_proba(X_test_summary)[:, 1]\n",
    "\n",
    "threshold = 0.5\n",
    "y_pred_lg_binary = (y_pred_lg >= threshold).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_test_summary, y_pred_lg_binary)\n",
    "confusion = confusion_matrix(y_test_summary, y_pred_lg_binary)\n",
    "classification_report_str = classification_report(y_test_summary, y_pred_lg_binary)\n",
    "roc_auc_lg_summary = roc_auc_score(y_test_summary, y_pred_lg)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Accuracy_lg:\", accuracy)\n",
    "print(\"Confusion Matrix_lg:\\n\", confusion)\n",
    "print(\"Classification Report_lg:\\n\", classification_report_str)\n",
    "print(\"ROC AUC Score_lg:\", roc_auc_lg_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "Accuracy_xgb: 0.8262065003282995\n",
      "Confusion Matrix_xgb:\n",
      " [[19261  4012]\n",
      " [  223   872]]\n",
      "Classification Report_xgb:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.83      0.90     23273\n",
      "           1       0.18      0.80      0.29      1095\n",
      "\n",
      "    accuracy                           0.83     24368\n",
      "   macro avg       0.58      0.81      0.60     24368\n",
      "weighted avg       0.95      0.83      0.87     24368\n",
      "\n",
      "ROC AUC Score of Gradient Boosting (XGBoost): 0.8933697837480751\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting (XGBoost) for Classification\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.1, 0.01],\n",
    "}\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(random_state=42)\n",
    "xgb_grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='roc_auc', cv=5)\n",
    "xgb_grid_search.fit(X_usampled_summary, y_usampled_summary)\n",
    "\n",
    "best_params = xgb_grid_search.best_params_\n",
    "best_xgb_model = xgb_grid_search.best_estimator_\n",
    "\n",
    "y_pred_gb = best_xgb_model.predict_proba(X_test_summary)[:, 1]\n",
    "\n",
    "threshold = 0.5\n",
    "y_pred_gb_binary = (y_pred_gb >= threshold).astype(int)\n",
    "\n",
    "roc_auc_gb_summary = roc_auc_score(y_test_summary, y_pred_gb)\n",
    "accuracy = accuracy_score(y_test_summary, y_pred_gb_binary)\n",
    "confusion = confusion_matrix(y_test_summary, y_pred_gb_binary)\n",
    "classification_report_str = classification_report(y_test_summary, y_pred_gb_binary)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Accuracy_xgb:\", accuracy)\n",
    "print(\"Confusion Matrix_xgb:\\n\", confusion)\n",
    "print(\"Classification Report_xgb:\\n\", classification_report_str)\n",
    "print(\"ROC AUC Score of Gradient Boosting (XGBoost):\", roc_auc_gb_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lr/2nfz4tks7jvdbfs0vc58q0x00000gn/T/ipykernel_32921/1513607251.py:28: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_classifier = tf.keras.wrappers.scikit_learn.KerasClassifier(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'learning_rate': 0.001, 'neurons_in_hidden': 32, 'neurons_in_input': 64}\n",
      "Accuracy: 0.5799086757990868\n",
      "Confusion Matrix:\n",
      " [[748 122]\n",
      " [614 268]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.86      0.67       870\n",
      "           1       0.69      0.30      0.42       882\n",
      "\n",
      "    accuracy                           0.58      1752\n",
      "   macro avg       0.62      0.58      0.55      1752\n",
      "weighted avg       0.62      0.58      0.54      1752\n",
      "\n",
      "ROC AUC Score of Neural Networks: 0.5818124951129877\n"
     ]
    }
   ],
   "source": [
    "# Neural Networks (Feedforward) for Classification\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve, precision_recall_curve\n",
    "\n",
    "def create_model(neurons_in_input, neurons_in_hidden, learning_rate):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(neurons_in_input, activation='relu', input_shape=(input_dim,), name='input_layer'),\n",
    "        tf.keras.layers.Dense(neurons_in_hidden, activation='relu', name='hidden_layer'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid', name='output_layer')\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
    "    return model\n",
    "\n",
    "input_dim = 300\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_usampled_summary, y_usampled_summary, test_size=0.2, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'neurons_in_input': [64, 128],\n",
    "    'neurons_in_hidden': [32, 64],\n",
    "    'learning_rate': [0.001, 0.01]\n",
    "}\n",
    "\n",
    "keras_classifier = tf.keras.wrappers.scikit_learn.KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "grid_search = GridSearchCV(keras_classifier, param_grid, cv=3, scoring='roc_auc')\n",
    "grid_search.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "y_pred_nn_summary = best_model.predict(X_test).flatten()\n",
    "\n",
    "threshold = 0.5\n",
    "y_pred_nn_binary_summary = (y_pred_nn_summary >= threshold).astype(int)\n",
    "\n",
    "roc_auc_nn_summary = roc_auc_score(y_test, y_pred_nn_summary)\n",
    "accuracy = accuracy_score(y_test, y_pred_nn_binary_summary)\n",
    "confusion = confusion_matrix(y_test, y_pred_nn_binary_summary)\n",
    "classification_report_str = classification_report(y_test, y_pred_nn_binary_summary)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\\n\", confusion)\n",
    "print(\"Classification Report:\\n\", classification_report_str)\n",
    "print(\"ROC AUC Score of Neural Networks:\", roc_auc_nn_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
